{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "üìöImporting libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.naive_bayes import MultinomialNB\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.base import BaseEstimator, TransformerMixin\n",
                "import string\n",
                "from nltk.corpus import stopwords\n",
                "from nltk.tokenize import word_tokenize\n",
                "from nltk.stem import WordNetLemmatizer\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package punkt to /home/gitpod/nltk_data...\n",
                        "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
                        "[nltk_data] Downloading package wordnet to /home/gitpod/nltk_data...\n",
                        "[nltk_data] Downloading package stopwords to /home/gitpod/nltk_data...\n",
                        "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import nltk\n",
                "nltk.download('punkt')\n",
                "import nltk\n",
                "nltk.download('wordnet')\n",
                "import nltk\n",
                "nltk.download('stopwords')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "‚ú®Data Ingestion"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>package_name</th>\n",
                            "      <th>review</th>\n",
                            "      <th>polarity</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>privacy at least put some option appear offli...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>messenger issues ever since the last update, ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>profile any time my wife or anybody has more ...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>the new features suck for those of us who don...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>com.facebook.katana</td>\n",
                            "      <td>forced reload on uploading pic on replying co...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "          package_name                                             review  \\\n",
                            "0  com.facebook.katana   privacy at least put some option appear offli...   \n",
                            "1  com.facebook.katana   messenger issues ever since the last update, ...   \n",
                            "2  com.facebook.katana   profile any time my wife or anybody has more ...   \n",
                            "3  com.facebook.katana   the new features suck for those of us who don...   \n",
                            "4  com.facebook.katana   forced reload on uploading pic on replying co...   \n",
                            "\n",
                            "   polarity  \n",
                            "0         0  \n",
                            "1         0  \n",
                            "2         0  \n",
                            "3         0  \n",
                            "4         0  "
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "total_data = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/naive-bayes-project-tutorial/main/playstore_reviews.csv\")\n",
                "total_data.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "‚ú®Preprocessing: Tokenization, removal of stop words and special characters, text normalization, and vectorization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['package_name', 'review', 'polarity'], dtype='object')"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "total_data.columns"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "üë©‚ÄçüíªStep 1: Tokenization and Stop Words Removal\n",
                "Tokenization: Divide the text into smaller units, such as words or phrases (tokens)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "                                              review  polarity  \\\n",
                        "0   privacy at least put some option appear offli...         0   \n",
                        "1   messenger issues ever since the last update, ...         0   \n",
                        "2   profile any time my wife or anybody has more ...         0   \n",
                        "3   the new features suck for those of us who don...         0   \n",
                        "4   forced reload on uploading pic on replying co...         0   \n",
                        "\n",
                        "                                      processed_text  \n",
                        "0  privacy least put option appear offline mean p...  \n",
                        "1  messenger issues ever since last update initia...  \n",
                        "2  profile time wife anybody one post view would ...  \n",
                        "3  new features suck us working back button guys ...  \n",
                        "4  forced reload uploading pic replying comment l...  \n"
                    ]
                }
            ],
            "source": [
                "stop_words = set(stopwords.words('english'))\n",
                "\n",
                "def preprocess_text(text):\n",
                "    # Tokenization\n",
                "    tokens = word_tokenize(text)\n",
                "    # Stop Words Removal\n",
                "    tokens = [word.lower() for word in tokens if word.isalpha() and word.lower() not in stop_words]\n",
                "    return ' '.join(tokens)\n",
                "\n",
                "total_data['processed_text'] = total_data['review'].apply(preprocess_text)\n",
                "#Show first 10 processed rows\n",
                "print(total_data[['review', 'polarity', 'processed_text']].head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "üë©‚ÄçüíªStep 2: Lemmatization (Optional)\n",
                "Lemmatization: Reduces words to their base forms (lemmas). For example, it converts \"running\" to \"run.\" Helps reduce the dimensions of the feature space by grouping related words."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "lemmatizer = WordNetLemmatizer()\n",
                "total_data['processed_text'] = total_data['processed_text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "üë©‚ÄçüíªStep 3: Removal of Special Characters and Punctuation\n",
                "Removal of Special Characters and Punctuation: Removes punctuation marks and special characters that generally do not contribute information to the task."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "total_data['processed_text'] = total_data['processed_text'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "üë©‚ÄçüíªStep 4: Text Normalization (Convert to lowercase)\n",
                "\n",
                "Text Normalization: Converts all text to lowercase. Helps treat uppercase and lowercase words as identical, reducing complexity."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "total_data['processed_text'] = total_data['processed_text'].apply(lambda x: x.lower())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "üë©‚ÄçüíªStep 5: Text Vectorization (Using TF-IDF)\n",
                "\n",
                "Text Vectorization (TF-IDF): Converts text into a numerical representation. TF-IDF assigns scores to words based on their frequency in a document and their inverse frequency in the corpus. This captures the relative importance of words in the document and the corpus"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "vectorizer = TfidfVectorizer(max_features=5000)  # Ajusta el n√∫mero m√°ximo de caracter√≠sticas seg√∫n sea necesario\n",
                "X = vectorizer.fit_transform(total_data['processed_text'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "üë©‚ÄçüíªStep 6: Removal of Rare or Very Frequent Words (Optional)\n",
                "\n",
                "Removal of Rare or Very Frequent Words: May be optional, but helps eliminate words that are very rare or very common in the corpus. Extremely rare words may not provide useful information, while extremely common words may not be discriminative"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, max_features=5000)\n",
                "X = vectorizer.fit_transform(total_data['processed_text'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Divide intro train and test set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "331      just did the latest update on viber and yet ...\n",
                            "733     keeps crashing it only works well in extreme ...\n",
                            "382     the fail boat has arrived the 6.0 version is ...\n",
                            "704     superfast, just as i remember it ! opera mini...\n",
                            "813     installed and immediately deleted this crap i...\n",
                            "Name: review, dtype: object"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "X = total_data[\"review\"]\n",
                "y = total_data[\"polarity\"]\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
                "X_train.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Save train and test data on disk."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train.to_csv('X_train.csv', index=False, header=True)\n",
                "X_test.to_csv('X_test.csv', index=False, header=True)\n",
                "y_train.to_csv('y_train.csv', index=False, header=True)\n",
                "y_test.to_csv('y_test.csv', index=False, header=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Transform the test into a matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([[0, 0, 0, ..., 0, 0, 0],\n",
                            "       [0, 0, 0, ..., 0, 0, 0],\n",
                            "       [0, 0, 0, ..., 0, 0, 0],\n",
                            "       ...,\n",
                            "       [0, 0, 0, ..., 0, 0, 0],\n",
                            "       [0, 0, 0, ..., 0, 0, 0],\n",
                            "       [0, 0, 0, ..., 0, 0, 0]])"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "vec_model = CountVectorizer(stop_words = \"english\")\n",
                "X_train = vec_model.fit_transform(X_train).toarray()\n",
                "X_test = vec_model.transform(X_test).toarray()\n",
                "\n",
                "X_train"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Naive Bayes üëâ MultinomialNB"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
                        ],
                        "text/plain": [
                            "MultinomialNB()"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from sklearn.naive_bayes import MultinomialNB\n",
                "\n",
                "model = MultinomialNB()\n",
                "model.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
                            "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
                            "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
                            "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
                            "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
                            "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
                            "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
                            "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
                            "       0, 0, 0])"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "y_pred = model.predict(X_test)\n",
                "y_pred"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.8156424581005587"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "accuracy_score(y_test, y_pred)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Save model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the model to disk\n",
                "import pickle\n",
                "with open('multinomial_nb_model.pkl', 'wb') as model_file:\n",
                "    pickle.dump(model, model_file)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Accuracy counter"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "GaussianNB() with accuracy: 0.8044692737430168\n",
                        "BernoulliNB() with accuracy: 0.770949720670391\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
                "\n",
                "for model_aux in [GaussianNB(), BernoulliNB()]:\n",
                "    model_aux.fit(X_train, y_train)\n",
                "    y_pred_aux = model_aux.predict(X_test)\n",
                "    print(f\"{model_aux} with accuracy: {accuracy_score(y_test, y_pred_aux)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "So, the best model should be: MultinomialNB reaching üëâ 0.81564245810055 of accuracy."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Hyperparams Tunning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=MultinomialNB(), n_iter=50,\n",
                            "                   param_distributions={&#x27;alpha&#x27;: array([ 0.01      ,  0.06020101,  0.11040201,  0.16060302,  0.21080402,\n",
                            "        0.26100503,  0.31120603,  0.36140704,  0.41160804,  0.46180905,\n",
                            "        0.51201005,  0.56221106,  0.61241206,  0.66261307,  0.71281407,\n",
                            "        0.76301508,  0.81321608,  0.86341709,  0.91361809,  0.9638191 ,\n",
                            "        1.0140201 ,  1.06422111,  1.11442211,  1.1646231...\n",
                            "        8.54417085,  8.59437186,  8.64457286,  8.69477387,  8.74497487,\n",
                            "        8.79517588,  8.84537688,  8.89557789,  8.94577889,  8.9959799 ,\n",
                            "        9.0461809 ,  9.09638191,  9.14658291,  9.19678392,  9.24698492,\n",
                            "        9.29718593,  9.34738693,  9.39758794,  9.44778894,  9.49798995,\n",
                            "        9.54819095,  9.59839196,  9.64859296,  9.69879397,  9.74899497,\n",
                            "        9.79919598,  9.84939698,  9.89959799,  9.94979899, 10.        ]),\n",
                            "                                        &#x27;fit_prior&#x27;: [True, False]},\n",
                            "                   random_state=42, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=MultinomialNB(), n_iter=50,\n",
                            "                   param_distributions={&#x27;alpha&#x27;: array([ 0.01      ,  0.06020101,  0.11040201,  0.16060302,  0.21080402,\n",
                            "        0.26100503,  0.31120603,  0.36140704,  0.41160804,  0.46180905,\n",
                            "        0.51201005,  0.56221106,  0.61241206,  0.66261307,  0.71281407,\n",
                            "        0.76301508,  0.81321608,  0.86341709,  0.91361809,  0.9638191 ,\n",
                            "        1.0140201 ,  1.06422111,  1.11442211,  1.1646231...\n",
                            "        8.54417085,  8.59437186,  8.64457286,  8.69477387,  8.74497487,\n",
                            "        8.79517588,  8.84537688,  8.89557789,  8.94577889,  8.9959799 ,\n",
                            "        9.0461809 ,  9.09638191,  9.14658291,  9.19678392,  9.24698492,\n",
                            "        9.29718593,  9.34738693,  9.39758794,  9.44778894,  9.49798995,\n",
                            "        9.54819095,  9.59839196,  9.64859296,  9.69879397,  9.74899497,\n",
                            "        9.79919598,  9.84939698,  9.89959799,  9.94979899, 10.        ]),\n",
                            "                                        &#x27;fit_prior&#x27;: [True, False]},\n",
                            "                   random_state=42, scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div>"
                        ],
                        "text/plain": [
                            "RandomizedSearchCV(cv=5, estimator=MultinomialNB(), n_iter=50,\n",
                            "                   param_distributions={'alpha': array([ 0.01      ,  0.06020101,  0.11040201,  0.16060302,  0.21080402,\n",
                            "        0.26100503,  0.31120603,  0.36140704,  0.41160804,  0.46180905,\n",
                            "        0.51201005,  0.56221106,  0.61241206,  0.66261307,  0.71281407,\n",
                            "        0.76301508,  0.81321608,  0.86341709,  0.91361809,  0.9638191 ,\n",
                            "        1.0140201 ,  1.06422111,  1.11442211,  1.1646231...\n",
                            "        8.54417085,  8.59437186,  8.64457286,  8.69477387,  8.74497487,\n",
                            "        8.79517588,  8.84537688,  8.89557789,  8.94577889,  8.9959799 ,\n",
                            "        9.0461809 ,  9.09638191,  9.14658291,  9.19678392,  9.24698492,\n",
                            "        9.29718593,  9.34738693,  9.39758794,  9.44778894,  9.49798995,\n",
                            "        9.54819095,  9.59839196,  9.64859296,  9.69879397,  9.74899497,\n",
                            "        9.79919598,  9.84939698,  9.89959799,  9.94979899, 10.        ]),\n",
                            "                                        'fit_prior': [True, False]},\n",
                            "                   random_state=42, scoring='accuracy')"
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import numpy as np\n",
                "from sklearn.model_selection import RandomizedSearchCV\n",
                "\n",
                "hyperparams = {\n",
                "    \"alpha\": np.linspace(0.01, 10.0, 200),\n",
                "    \"fit_prior\": [True, False],\n",
                "    #\"class_prior\": [None, [0.3, 0.7]],  # Vlues\n",
                "}\n",
                "\n",
                "random_search = RandomizedSearchCV(model, hyperparams, n_iter = 50, scoring = \"accuracy\", cv = 5, random_state = 42)\n",
                "random_search"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Printing best Hyperparameters"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Best hyperparameters: {'fit_prior': False, 'alpha': 1.917638190954774}\n"
                    ]
                }
            ],
            "source": [
                "random_search.fit(X_train, y_train)\n",
                "\n",
                "print(f\"Best hyperparameters: {random_search.best_params_}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Accuracy testing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.8212290502793296"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model = MultinomialNB(alpha = 1.917638190954774, fit_prior = False)\n",
                "model.fit(X_train, y_train)\n",
                "model.fit(X_train, y_train)\n",
                "y_pred = model.predict(X_test)\n",
                "accuracy_score(y_test, y_pred)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now the model is performing something better than the one above: \n",
                "Without hyperparams tunning üëâ0.81564245810055\n",
                "With hyperparams tunning üëâ 0.8212290502793296"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Save optimized model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Accuracy del modelo: 0.8212290502793296\n"
                    ]
                }
            ],
            "source": [
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "print(f'Accuracy del modelo: {accuracy}')\n",
                "\n",
                "with open('multinomial_nb_model_with_tunning_fit_prior_False_alpha_1.917638190954774.pkl', 'wb') as model_info_file:\n",
                "    pickle.dump({'model': model, 'accuracy': accuracy}, model_info_file)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
